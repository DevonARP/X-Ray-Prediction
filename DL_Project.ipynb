{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7443f76-aa7b-48db-b15f-097fadc15b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F \n",
    "from torchvision import transforms as T,datasets,models\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "from torch.nn import ConvTranspose2d\n",
    "from torch.nn import BatchNorm2d\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import LeakyReLU\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Tanh\n",
    "from torch.nn import Sigmoid\n",
    "from torch import flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4570ea6a-5547-4a86-aedd-f6bd10293f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "torch.use_deterministic_algorithms(True) # Needed for reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23983dd6-9bde-4153-8a14-1a38bef83dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transforms(phase = None):\n",
    "    \n",
    "    if phase == TRAIN:\n",
    "\n",
    "        data_T = T.Compose([\n",
    "            \n",
    "                T.Resize(size = (256,256)),\n",
    "                T.RandomRotation(degrees = (-20,+20)),\n",
    "                T.CenterCrop(size=224),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    elif phase == TEST or phase == VAL:\n",
    "\n",
    "        data_T = T.Compose([\n",
    "\n",
    "                T.Resize(size = (224,224)),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "    return data_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b2e5664-95f4-4206-bb2b-f63f3eb49e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"C:/Users/Anil/Downloads/archive/chest_xray\"\n",
    "TEST = 'test'\n",
    "TRAIN = 'train'\n",
    "VAL ='val'\n",
    "\n",
    "trainset = datasets.ImageFolder(os.path.join(data_dir, TRAIN),transform = data_transforms(TRAIN))\n",
    "testset = datasets.ImageFolder(os.path.join(data_dir, TEST),transform = data_transforms(TEST))\n",
    "validset = datasets.ImageFolder(os.path.join(data_dir, VAL),transform = data_transforms(VAL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38c0be92-1974-4f4a-943e-ff36b11cb551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NORMAL', 'PNEUMONIA']\n",
      "{'NORMAL': 0, 'PNEUMONIA': 1}\n"
     ]
    }
   ],
   "source": [
    "class_names = trainset.classes\n",
    "print(class_names)\n",
    "print(trainset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f962802f-e7f9-424d-950d-526530b5d90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "trainloader = DataLoader(trainset,batch_size = 64,shuffle = True)\n",
    "validloader = DataLoader(validset,batch_size = 64,shuffle = True)\n",
    "testloader = DataLoader(testset,batch_size = 64,shuffle = True)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcc998bc-1dc0-4ac3-981c-bdd84a054ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (images,labels) in enumerate(trainloader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1962d7c2-30e3-4f3a-86a5-4da38bad068b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 224, 224]), torch.Size([32]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7806aff4-e905-4338-aa1c-7996fabf20db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # Input is 1 x 64 x 64\n",
    "            nn.Conv2d(3, 64, (4, 4), (2, 2), (1, 1), bias=True),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            # State size. 64 x 32 x 32\n",
    "            nn.Conv2d(64, 128, (4, 4), (2, 2), (1, 1), bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            # State size. 128 x 16 x 16\n",
    "            nn.Conv2d(128, 256, (4, 4), (2, 2), (1, 1), bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            # State size. 256 x 8 x 8\n",
    "            nn.Conv2d(256, 512, (4, 4), (2, 2), (1, 1), bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            # State size. 512 x 4 x 4\n",
    "            nn.Conv2d(512, 1, (4, 4), (1, 1), (0, 0), bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.main(x)\n",
    "        out = torch.flatten(out, 1)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0e3ab70e-2cd9-4189-98aa-f8421af70a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "69368adc-4439-4233-bfa4-068844472f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Discriminator()\n",
    "# defining the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "# defining the loss function\n",
    "criterion = nn.BCELoss()\n",
    "# checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "46dbfdb4-2509-4d16-a23c-52ea9a068e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Discriminator()\n",
    "# defining the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, betas=(0.5, 0.999))\n",
    "# defining the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c0f5419d-bd19-459d-8304-e9af71504596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (12): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f6f3365a-fb02-4ebd-9d38-89487418354a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           3,136\n",
      "         LeakyReLU-2         [-1, 64, 112, 112]               0\n",
      "            Conv2d-3          [-1, 128, 56, 56]         131,072\n",
      "       BatchNorm2d-4          [-1, 128, 56, 56]             256\n",
      "         LeakyReLU-5          [-1, 128, 56, 56]               0\n",
      "            Conv2d-6          [-1, 256, 28, 28]         524,288\n",
      "       BatchNorm2d-7          [-1, 256, 28, 28]             512\n",
      "         LeakyReLU-8          [-1, 256, 28, 28]               0\n",
      "            Conv2d-9          [-1, 512, 14, 14]       2,097,152\n",
      "      BatchNorm2d-10          [-1, 512, 14, 14]           1,024\n",
      "        LeakyReLU-11          [-1, 512, 14, 14]               0\n",
      "           Conv2d-12            [-1, 1, 11, 11]           8,193\n",
      "          Sigmoid-13            [-1, 1, 11, 11]               0\n",
      "================================================================\n",
      "Total params: 2,765,633\n",
      "Trainable params: 2,765,633\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 28.33\n",
      "Params size (MB): 10.55\n",
      "Estimated Total Size (MB): 39.45\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (images.shape[1], images.shape[2], images.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ca22321b-b65e-4e06-9e39-e081de016a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training loss: 3.9823245507914846\n",
      "Epoch 2 - Training loss: 3.9056651127047655\n",
      "Epoch 3 - Training loss: 3.8978060629309677\n",
      "Epoch 4 - Training loss: 3.877935586906061\n",
      "Epoch 5 - Training loss: 3.8763193967865734\n",
      "Epoch 6 - Training loss: 3.8723122870049824\n",
      "Epoch 7 - Training loss: 3.869204820656195\n",
      "Epoch 8 - Training loss: 3.8690920602984544\n",
      "Epoch 9 - Training loss: 3.865574778580084\n",
      "Epoch 10 - Training loss: 3.8641761454140267\n",
      "Epoch 11 - Training loss: 3.862699633691369\n",
      "Epoch 12 - Training loss: 3.868286225853897\n",
      "Epoch 13 - Training loss: 3.8691616610782904\n",
      "Epoch 14 - Training loss: 3.862164712533718\n",
      "Epoch 15 - Training loss: 3.8647617392423674\n",
      "Epoch 16 - Training loss: 3.866307119043862\n",
      "Epoch 17 - Training loss: 3.867079083512469\n",
      "Epoch 18 - Training loss: 3.8583983502736907\n",
      "Epoch 19 - Training loss: 3.8673737863215005\n",
      "Epoch 20 - Training loss: 3.8618366049557196\n"
     ]
    }
   ],
   "source": [
    "Losses = []\n",
    "for i in range(20):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        \n",
    "        #Changing images to cuda for gpu\n",
    "        if torch.cuda.is_available():\n",
    "          images = images.cuda()\n",
    "          labels = labels.cuda()\n",
    "\n",
    "        # Training pass\n",
    "        # Sets the gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        #This is where the model learns by backpropagating\n",
    "        # accumulates the loss for mini batch\n",
    "        loss.backward()\n",
    "        \n",
    "        #And optimizes its weights here\n",
    "        optimizer.step()\n",
    "        Losses.append(loss)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(i+1, running_loss/len(trainloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e94469c5-de8a-4993-800a-9305681603f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Images Tested = 624\n",
      "\n",
      "Model Accuracy = 0.36538461538461536\n"
     ]
    }
   ],
   "source": [
    "correct_count, all_count = 0, 0\n",
    "for images,labels in testloader:\n",
    "  for i in range(len(labels)):\n",
    "    if torch.cuda.is_available():\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "    img = images[i].view(1, 3, 224, 224)\n",
    "    with torch.no_grad():\n",
    "        logps = model(img)\n",
    "\n",
    "    \n",
    "    ps = torch.exp(logps)\n",
    "    probab = list(ps.cpu()[0])\n",
    "    pred_label = probab.index(max(probab))\n",
    "    true_label = labels.cpu()[i]\n",
    "    if(true_label == pred_label):\n",
    "      correct_count += 1\n",
    "    all_count += 1\n",
    "\n",
    "print(\"Number Of Images Tested =\", all_count)\n",
    "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7383fd97-865b-4c93-824f-24a5f4ed9952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
